==Overview==
SemPrMM is a multimodal imaging (MEG-EEG and fMRI) project with healthy adults and schizophrenia patients begun in Fall 2010. This project includes the 'Baleen' and 'MaskMM' paradigms. Ellen is the PI of an NIH NRSA supporting her salary to pursue the Baleen project.  Scan time and additional support is provided by other sources including Gina's R01, for which 'MaskedMM' and the inhibition/conflict measures we are collecting are relevant. 

The theoretical focus of Baleen is to understand the neural mechanisms involved in top-down prediction and lexical selection in language comprehension, and how these mechanisms are impacted in schizophrenia patients, who are known to have difficulties in using the broader context for processing. A critical ''methodological'' focus is to study the relationship between MEG-EEG evoked responses and fMRI responses, a relationship which is still very poorly understood.

Ellen's grant proposes two main studies. One is the semantic priming study which will be conducted first, which manipulates prediction by manipulating the proportion of related stimuli across the experiment. If this is successful, a second study will manipulate prediction in a more natural language comprehension situation of reading sentences. The first, semantic priming study is what we are calling '''Baleen'''. Testing sessions will also include a masked priming paradigm relevant for Gina's R01 ('''MaskedMM'''), and a short functional localizer paradigm of words and sentences ('''ATLLoc''').

SemPrMM studies involve 2 neuroimaging sessions per subject on separate days, one of fMRI and one of MEG/EEG. Schizophrenia patients come in for at least one additional session to be given multiple written assessments.

This is the first study using [[VTSD]] for stimulus presentation.

===Related Pages===

*   [[SemprMM Procedures]] provides detailed information about procedures related to running the study.
*   [[SemPrMM 1st Level]] provides a detailed explanantion of how to go about MRI processing a single subject from DICOM images to first-level statistics using both the SPM and FSFast pipelines.
*   [[SemPrMM Analysis Settings]] explains all of the settings pertaining to our analysis streams.

==Paradigms==

===ATLLoc===

This is a language localizer. It contrasts lists of consonant strings, lists of words, and sentences, all of these trials being 9 items long. It is called ATLLoc because the sentence - word contrast should elicit Anterior Temporal Lobe contrast.

====Design====

20 9-word items in 3 conditions
* sentences
* noun lists
* nonword lists

Just two lists, for the two sessions. Half of the sentences and noun lists from each are taken from Rogalsky & Hickok (these are numbered 101-120 and 201-220). The other half for the sentences are based around the frames from the original sentences, with different content words. The other half for the words are nouns that didn't appear in the rest of the experiment. 

The nonword lists include 9 consonant strings, matched in length to the words from the word list in the other session. 

The two lists without optseq schedules are in stims/ATLLoc/ATL_101 and ATL_102.

Just need one run.

====Task====

No task

====Presentation Parameters====

  fixation (200) -  blank (200) - word1 (300) - blank (100) - word2 (300) - blank (100) - ... word9 (300) - blank (100) - optional 700 ms blank for MEG blinking
  total time 9*400 = 3600. 3600+400 = 2000 = TR.
  60 trials x 4 seconds = 240 seconds = 4 minutes, plus null event time

====Condition Codes====
  1 = sentences
  2 = noun lists
  3 = consonant string lists

=====MEG Codes=====
  Trigger condition code on blank preceding first word. <br>
  Trigger 4 on all the words.

====Optseq Codes====

We have 20 trials x 3 conditions, each trial is 4 seconds long. So the ntp is 60 x 2 + 20 null trials x 2  = 160. True length of experiment is 320 sec, 5:20.

  optseq2 --ntp 160 --tr 2 --psdwin -6 22 2\
  --ev 1 4 20 \
  --ev 2 4 20 \
  --ev 3 4 20 \
  --nkeep 2 --o ATLLoc --nsearch 10000 --focb 100 --polyfit 2

===MaskedMM===
Materials set from Kreher et al 2006 Psychophysiology, with a few items deleted or changed, with presentation parameters changed and masking added, and with the food probes changed to insect probes

====Design====
Priming experiment, 3 conditions: 
*related (TIGER-STRIPES)
*indirectly related (LION - STRIPES)
*unrelated (LAMP - STRIPES)
64 items per 3 conditions, plus about 40 insect probe items

====Task====
Press a button as quickly as you can if you see an insect word. 
* Following original materials, insect word can be on prime or target, and this allows you some measure of the consciousness of the prime.

====Presentation Parameters====
  fixation 400 - blank 200 - forMask 300 - prime 80 - backMask 20 - target 300 - blank 700 - optional 500 ms extra blank for MEG to allow 1200 ms for blinks

* SOA = 100 ms <br>
  
* Masks are hash marks of the length of the longest prime

====Condition Codes====
  1 - directly related
  2 - indirectly related 
  3 - unrelated
  4 - insect prime 
  5 - insect target 

=====MEG Codes=====

Same as above for targets
* Trigger 14 for primes

====Optseq Codes====

We have 2 runs with 32 items per target condition per run (32 x 3 = 96), plus 10 probe prime (4) and 10 probe target (5) for a total of 116 items per run. We have 3 lists, so we need a total of 6 schedules. We need 32 null events to match the 32 in the other conditions, which gives us a total of 148 time points.

  optseq2 --ntp 148 --tr 2 --psdwin -6 18 2 \
  --ev 1 2 32 \
  --ev 2 2 32  \
  --ev 3 2 32 \
  --ev 4 2 10 \
  --ev 5 2 10 \
  --nkeep 6 --o MaskMM --nsearch 10000  --focb 100 --polyfit 2

===BaleenMM===
====Design====
2 x 2 design (priming x proportion)
40 items per 4 conditions, plus tons of fillers
*Block1: low proportion, includes 40 related targets and 40 unrelated targets 
*Block2: high proportion, includes 40 related targets and 40 unrelated targets

Each block has 4 runs for a total of 8 runs

* The 2 sessions are identical in structure but have completely different stimuli.

* The main analysis is on the target words in the 4 conditions of interest. For each session we have 4 different possible lists that a subject could get. That’s because each individual target word, like ‘PEPPER’ needs to appear in each of the 4 conditions across different subjects: lowProp Related, highProp Related, lowProp Unrelated, and highProp Unrelated. 

For example:
Subject 1 - sees SALT-PEPPER in lowProp Block
Subject 2 - sees SALT-PEPPER in highProp Block
Subject 3 - sees PLUS-PEPPER in lowProp Block
Subject 4 - sees PLUS-PEPPER in highProp Block

Item lists will be created in text files, each row should have a prime, target, and condition code. The Psychtoolbox script just reads in these text files.

* In fMRI, regular trials will be interspersed with fixation trials of different durations according to optseq algorithm. The total time in fixation trials = the time it takes to present 40 regular trials.

====Task====
Subjects are instructed to press a button as quickly as they can whenever they see an animal word. Animal words are always targets...this allows us to look at the effect of prediction on the animal probes across lowProp and highProp blocks.

* The presentation script does not wait for a response to proceed, because there is no overt response on non-animal trials. 

====Presentation Parameters====
  Fixation 200 - Blank 200 -  Prime 500 - Blank 100 - Target 900 - Blank 100 - optional  700 ms for MEG blink

'''SOA''' = 600 ms <br>
'''Total trial time''' = 2000 ms = TR

* Blinking doesn't matter in fMRI, so we don't spend so much time on the fixation; the null trials provide a chance to rest.
* In MEG, we add a constant 700 ms to end of each trial so that people have a chance to blink. Note this makes the MEG session somewhat longer (although no null trials).

====Condition Codes====
  Low Proportion 
    1 - Related Target - n=40
    2 - Unrelated Target - n=40
    4 - Unrelated Filler - n=240
    5 - Animal Target - n=40
    11 - Animal Prime - n=40

  High Proportion
    6 - Related Target - n=40
    7 - Unrelated Target - n=40
    8 - Related Filler - n=160
    9 - Unrelated Filler - n=80
    10 - Animal Target - n=40
    12 - Animal Prime - n=40

=====MEG Codes=====
Same as above trigger on target presentation
* Trigger 14 on primes

====Optseq Codes====

Doug Greve recommended that we use 30 null events per run, for a total of 130 time points. Doug said that we can just sample the HDR at multiples of our TR (every 2 seconds) so we have more power, we don't need to sample it every second.  We need 32 schedules per distribution, for the 4 runs x 8 lists -- this is specified in ''nkeep''. 

Per run, in the low relatedness distribution we have 10 related targets (1), 10 unrelated targets (2), 10 animal primes (11), 10 animal targets (5), and 60 unrelated fillers (4). This is specified in the --ev codes. All the events are 2 seconds in duration.

  optseq2 --ntp 130 --tr 2 --psdwin -6 18 2 \
  --ev 1 2 10 \
  --ev 2 2 10  \
  --ev 4 2 60 \
  --ev 5 2 10 \
  --ev 11 2 10 \
  --nkeep 32 --o baleenLo --nsearch 10000  --focb 100 --polyfit 2

Per run, in the high relatedness distribution we have 10 related targets (6), 10 unrelated targets (7), 10 animal primes (12), 10 animal targets (10), 40 related fillers (8) and 20 unrelated fillers (9). Because most of our stuff is about 10, we can use 10 null events, for a total of 110 time points.

  optseq2 --ntp 130 --tr 2 --psdwin -6 18 2 \
  --ev 6 2 10 \
  --ev 7 2 10  \
  --ev 8 2 40 \
  --ev 9 2 20 \
  --ev 10 2 10 \
  --ev 12 2 10 \
  --nkeep 32  --o baleenHi   --nsearch 10000  --focb 100 --polyfit 2

====Stimuli Creation====
The stimuli pairs for each condition type were created for the Baleen ERP pilot using a lot of Python scripts. The output was text files for each stimuli type which are located in /cluster/kuperberg/SemPrMM/stims/BaleenMM/stimLists/rawMaterials. 

We then used a Python script called 'makeFinalLists.py' to group stimuli by list and block (Lo or Hi). These 'block lists' are located in /cluster/kuperberg/SemPrMM/stims/BaleenMM/stimLists/blockLists.

We then used a Python script called 'makeStimLists.py' to combine those blocks together and keep only the necessary information for stimulus presentation (prime, target, item code and condition code). This resulted in stimuli lists (101-104 for Session 1 materials and 201-204 for Session 2 materials) that are located in /cluster/kuperberg/SemPrMM/stims/BaleenMM/stimlists.

Finally, we used a Python script called 'makeSchedules.py' to create the input files to PsychToolbox with timing and order information based on the Optseq schedules. These files--8 runs for each list--'''are the direct input to stimulus presentation''', and are located in /cluster/kuperberg/SemPrMM/stims/Baleen/psychTB.

All of these scripts are located in /cluster/kuperberg/SemPrMM/stims/BaleenMM/stimScripts.

<br>


===AX-CPT===

This is a cognitive task that looks at inhibition and use of context, developed by Jonathan Cohen and colleagues. There are 4 conditions, schematically illustrated as AX, AY, BX and BY. Letters are presented one at a time at a constant pace, and participants respond with a button press only when they see the sequence A-X. There must be 70% of A-X trials to get conflict in responding to the B-X or A-Y trials (in fact, the Bs and Ys can be any letter that is not visually similar to X).

In our study, to get the minimum 40 trials per condition you need for MEG, we have:

  AX - 280
  AY - 40
  BX - 40
  BY - 40 

We have this divided into two runs of 200 stims each (where a stim is considered this kind of pair).

====Presentation Parameters====

  A/B 250 ms - blank 750 ms - X/Y 250 ms - blank 750 ms - optional null event ITI in fMRI

This is the only task where, in MEG, we have inserted blinking trials instead of using the ITI

====Condition Codes====

  AY - 1
  BX - 2
  BY - 3
  AX - 4
  (MEG)
  A - 5
  B - 6

====Optseq Codes====

We have 2 runs with 20 items per AY, BX, BY conditions per run, plus 140 AX trials per run, for a total of 200 trials per run. We have 2 lists, so we need a total of 4 schedules. We'll use 40 null events, which gives us a total of 240 time points. That is 480 seconds, which is 8:00.

  optseq2 --ntp 240 --tr 2 --psdwin -4 16 2 \
  --ev 1 2 20 \
  --ev 2 2 20  \
  --ev 3 2 20 \
  --ev 4 2 140 \
  --nkeep 4 --o  AXCPT --nsearch 10000  --focb 100 --polyfit 2

For patients, we are dividing up into 3 runs, with 12 items per AX, BX, BY conditions per run, plus 74 AX trials per run, for a total of 110 trials per run. We'll use 30 null events, which gives us a total of 140 time points per run. That is 280 seconds, which is 4:40. We have 2 lists, so we need a total of 6 schedules.

  optseq2 --ntp 140 --tr 2 --psdwin -4 16 2 \
  --ev 1 2 12 \
  --ev 2 2 12  \
  --ev 3 2 12 \
  --ev 4 2 74 \
  --nkeep 6 --o  AXCPT --nsearch 10000  --focb 100 --polyfit 2

==Behavioral Assessments==

We will do several behavioral assessments on inhibition and working memory. WM-Span goes before the first scanning session. Stop-signal goes after the first scanning session. AntiSaccade goes after the second scanning session.

===Working Memory Span===

We will present this with VTSD. The VTSD script allows us to score the number of hits automatically, but we will also record the sequence of the responses manually in case we need it for future reference. 

===Stop-signal===

Inhibition task that you can download from this website: http://users.ugent.be/~masteven/tscope/stop.html. It only runs on PC but it's free. Works on Ellen's Parallels. Have tested and seems straightforward to run, you just need to enter Full-screen mode in Parallels before you start running it. Analysis also looks straightforward although it's kind of black-box, the program does it for you.

===AntiSaccade===

Currently runs in self-contained program on OSX. This task does the antisaccade but with manual responses.

==Scanning Parameters==
===MEG/EEG===

Stored under 'project' sempr_mm

* Sampling rate: 600 Hz
* Online low-pass: 200 Hz
* Online high-pass: .03 Hz

===MRI/fMRI===

Scanner: Bay 6 (aka Bay 8)
3T Siemens TIM Trio 60 cm (RF coil ID) 32 channel MRI. 

====Structural====

=====MPRAGE=====
{|border="1" cellspacing="0" cellpadding="5" 
!type
!parameters
!prev studies
!current study
!notes
|-
|rowspan=5| Timing etc || TR || 7.25 ms - HBM, 2530 ms - NI08, MT || || 
|-
| TE || 3 ms - HBM,  multiple echo - NI08, MT || || 
|-
| flip angle || 90 - HBM, 7 - NI08, MT  || || 
|-
| scanning time || 6 min - MT || || 
|-
| phase encoding direction || AP - MT || || 
|-

|rowspan=5| spatial resolution ||  # slices || 128 - NI08, HBM, MT || || 
|-
|slice thickness || 1 mm - all ||  || 
|-
|inter-slice interval || ?  ||  || 
|-
|in-plane resolution || not clear  ||  || 
|-
|FOV || total + x-by-x matrix ||  || 
|-

|rowspan=2| acquisition order ||  sequential or interleaved || interleaved ||  || 
|-
|ascending or descending ||  || || 
|-


|}

=====FLASH=====
* 5 degree FLASH scans.
<BR>

====Functional====

{|border="1" cellspacing="0" cellpadding="5" 
!type
!parameters
!prev studies
!current study
!notes
|-
|rowspan=5| Timing etc || TR ||  2 sec || 2 sec ||  field standard
|-
| TE || 25 ms - all|| 25 ms || 
|-
| flip angle || 90 - MT, HBM, 100 - NI08 || 90 || 
|-
| scanning time || variable  || || 
|-
| phase encoding direction || A -> P || A -> P || 
|-

|rowspan=5| spatial resolution ||  # slices || 30 - NI08, 33 - HBM, MT || 38 || 
|-
|slice thickness || 3mm - MT ||  || 
|-
|inter-slice interval || ? - MT, 1mm - NI08, .9mm - HBM ||  || 
|-
|in-plane resolution || 3.1x3.1 - MT, 3.13 x 3.13 - HBM, 3.125 x 3.125 - NI08 ||  || 
|-
|FOV || total + x-by-x matrix ||  || 
|-

|rowspan=2| acquisition order ||  sequential or interleaved ||  ||  || 
|-
|ascending or descending ||  || || 
|-


|}

====Other====
* '''FIELD MAP'''

==Running==

===Scheduling===
* MRI and MEG slots are scheduled lab-internally on the '''SemPrMM''' google calendar. 

* The REAL facilities schedule can be accessed [https://nmr.mgh.harvard.edu/facility/schedule/index.html here]. If we cannot use a slot it '''MUST''' be cancelled ahead of time and we '''MUST''' send a message to the scanner list. If we finish early we '''MUST''' send a message to the scanner list so that someone else can use the time. If we do not do these things we will be charged extreme amounts of money for time that we are not using to collect data!

* To schedule MEG in October, we need to look for free slots on the weekends etc. Once you are sure you can get a participant in, just go into the website above and grab the slot with our scanner account code.

===MRI Procedure===

#Localizer scan  (~1 min)
#SNR (~1 min)
#MEMPRAGE  (6:03)
#FIELDMAP (~1 min)
#ATLLoc (5:28)
#MaskedMM (5:04 x 2 =10:08)
#Baleen (4:28 x 8 = 35:44)
#AX-CPT (8:08 x 2 = 16:16)
#FLASH 5 (8:30)
#MEMPRAGE (6:03) (if time)

==Data Collection==

===Data Storage===
All of the data from the study is stored in /cluster/kuperberg/SemPrMM
*Data from behavioral assessments (stop-signal, anti-saccade, WMSpan) is in /assessment.
*MEG data is in /MEG
*MRI and fMRI data is in /MRI

===Acquisition Problems===
Major acquisition problems in any part of the dataset for each individual are logged in /assessment/SubjectLog.xlsx.

====Stimuli List Issues with MaskedMM====
For the first two MRI subjects (ya1 and ya2) the stimuli lists for MaskedMM were not counterbalanced correctly. Therefore, a slightly uneven number of each condition were presented. We re-did the lists on 10/15 so that they were counterbalanced correctly; however, the second consequence was that ya1 and ya2 were likely to have seen some of the same prime-target pairs in their second session of MEG. 

====MEG Trigger Issues with MaskedMM====
For the first three MEG subjects (ya1, ya3, and ya4), we sent triggers during MaskedMM that were tied to the timing of the mask presentation (the forward mask and the backward mask) instead of the timing of the prime and target presentation. Although the timing of the triggers was fairly tight with respect to the presentation of the mask (<1 ms of spread), they can't be used to determine the timing of the target because of the timing issue discussed in the next section--on ~1/6 trials the SOA between backward mask and target is 17 ms longer than expected. We did not log the presentation times of prime and target in the Matlab logfile for these subjects, so we can't determine which trials this happened on. Therefore, we probably cannot use the MaskedMM MEG data for these first three subjects.

====Timing issues with MaskedMM====
At the same time that we discovered the trigger issue, we discovered that because of the very brief presentation of the backward mask, we were not always able to achieve our desired timing. We request Matlab to present the prime for ~84 ms and the backward mask for ~16 ms before the target, but on about 1/6 of the trials, Matlab presents the backward mask for an extra screen refresh, so 32 ms instead of 16 ms. There is no net loss of time across the script because when this happens, VTSD shortens the next fixation cross by 16 ms to compensate.

Psychologically, this is probably not too impactful--it means changing from 100 ms SOA to 116 ms SOA, both of which are firmly in the 'short SOA' category. For fMRI recording, this timing variability is not really a problem because the time constant of the measurement is so much longer that we are considering the whole trial as a single event. For MEG recording, this timing variability is not a problem as long as the trigger is associated with the real presentation time of the target, whether it is 'on time' or delayed by 16 ms. However, just to be safe, we began logging all real presentation times of each stimulus in the Matlab logfile for all sessions run after 10/28/10.

====Electrode coding issues in MEG====
For the first four MEG subjects (ya1, ya3, ya4, ya7) in the settings file the electrodes were coded slightly incorrectly. In particular the two EOG and the ECG measurements were coded as EEG channels instead of EOG and ECG, and data from two channels that were not recording brain data were still being saved. This causes three problems:

#First, because MNE doesn't know which are the EOG channels, operations like artifact rejection and average reference won't be able to use or exclude them, respectively. To solve this problem, you can create an alias file changing those 7 channels and '''their type''' and run ''mne_rename_channels''. An example is in ''/MEG/scripts/alias1.txt.''
#Second, because the acquisition software thinks the EOG and ECG electrodes are EEG channels, they got incorrectly associated with the digitized EEG positions. This results in a mis-mapping of all the localization information for every EEG electrode after 60. To solve this, after you have renamed the channels in step 1, run the command ''mne_check_eeg_locations --file filename_raw.fif --fix''. This will re-associate the electrodes with the digitized points. Note that to do this, the electrodes still need to be named 'EEG ###', so if you are planning on renaming them to the 10-20 system names, you need to wait and do that after this step.
#Third, there are different numbers of channels containing data in different subjects, which can cause grand-averaging to fail in Matlab. To resolve this, you need to include a step in Matlab that deletes rows 390 and 379 (in that order) in the evoked.epoch array, so you get a total of 390 channels instead of 392.

====Ground Site====
For the first two MEG subjects, we put the ground on the mastoid because the lead wouldn't reach to the collarbone. Now the binding has been cut so after that, everyone has the ground on the collarbone.

====Trigger Coding in MEG for AXCPT====
For MEG subjects ya6 in AXCPT we had coded all of the targets as '8' instead of 1-4 for the 4 conditions. This is recoverable by using the VTSD file to determine which code the 8 should be substituted with.

For many subjects we were coding the first blink in a blink sequence as '6' and the second as '7'. this is recoverable by changing all the '6's preceding '7's to '7s'.

====Blinking issues in MEG====
For the first 15 MEG subjects (through ya19) we asked people to blink after every trial in MaskedMM and Baleen. However, at this point we realized we were having some problems with people blinking too soon after the target word had been presented. So at this point we switched to asking people to blink after every other trial, and giving them slightly longer to blink. This required changing the parameter file to have a 0 where the old blink interval had been, and inserting code to present the blink interval every other trial.

==Preprocessing==

===Behavioral===

Accuracy is computed with the scripts ''/cluster/kuperberg/SemPrMM/MRI/scripts/log2accuracy'' and ''/cluster/kuperberg/SemPrMM/MEG/scripts/eve2accuracy''. These output summary text files of average accuracy for each subject and condition in ''/cluster/kuperberg/SemPrMM/MRI/scripts/MRI_*_accuracy.log'' and ''/cluster/kuperberg/SemPrMM/MEG/scripts/MEG_*_accuracy.log''.

===MRI===

See [[SemPrMM_1st_Level]] for a detailed explanation for processing a subject through the first level statistics.<br>
See [[SemPrMM_Analysis_Settings]] for details on the exact settings used in both the SPM and FSFast pipelines.

===MEG===

Made an electrode location layout for us from ya1's digitization by using 

mne_make_eeg_layout --fif ya1_Blink_raw.fif --lout $HOME/.mne/lout/ya1_70elec.lout

Scripts are in /cluster/kuperberg/SemPrMM/MEG/scripts

====Procedure====

[[Image:Screen shot 2010-12-01 at 10.08.49 AM.png|thumb|Description]]

=====Timecourse=====
#Determine if any bad channels need to be marked, and save them in 'ya##_bad_chan.txt' in their data directory
##Look at logsheet from that day
##Open up several datafiles and look at them by hand
###If you have run preProc1 already, you will need to load a special selection file to see the EEG data b/c the channel names have changed
##Put name of each bad channel as one line in text file, e.g. 'MEG 0422'
###For EEG, use the 'PZ' type of labeling system to indicate bad channels rather than 'EEG 061', because this is what we will be using in the rest of the analysis
# ICA Decomposition & Automatic Blink Detection
## We've found that when decomposing EEG data into ICA space, that blink artifacts reliably fall into the first ICA component.
## Using this, we wrote a script to run ICA on all .fif files and then write out a list of samples that correspond to the peak of the blink artifact.
### The script is called run_all_ica.m and is found in (SemPrMM)/MEG/scripts/. You need to make some additions to your startup.m file to be able to use this script.
#### Open matlab from the commandline (not required, but seems to run faster) like 'matlab -nodisplay -nosplash -nodesktop'
#### cd to /cluster/kuperberg/SemPrMM/MEG/scripts
#### >> run_all_ica({'[subj_id]'}) (notice the curly brackets, this function takes a cell (so if you need be, you could pass in many subjects))
#### This function takes a while to run (between 1 and 2 hours)
#### The final output of this function is *.blinks which is just a list of samples that subsequent pipeline pieces can use.
#Run /scripts/preProc $subjID preBlinkTime postBlinkTime, which does the following:
##Makes a read-only copy of the raw data files in 'raw_backup'
##Extracts events read from .fif files into .eve text files
##Calls python script to recode some of the triggers so that we can make the bins needed for analysis
###This script also adds the 31.2 ms that we measured with the oscilloscope between the trigger being sent and the image appearing on the screen.
##Reclassifies the EOG channels in subjects where that was messed up
##Relabels the EEG channels from numbers to 10-20 names like CZ
##In the raw files, marks the bad channels listed in 'ya##_bad_chan.txt'
##Msake the basic average, Mod+blink.eve files, and noise covariance files
##preBlinkTime and postBlinkTime defines how wide you think the blink is--the ICA gives you the peak of the blink, and you decide how much space around the peak is corrupted by the blink
##gradRej has been hardcoded where appropriate to be 2500e-13
##Make sure you are running Python 2.6.3 or later!
##Calls python script 'makeAveFiles.py' to make the average parameter files
##Calls python script 'blinkEvefiles.py' to modify *Mod.eve files to *Modblink.eve files
###Slides a window for all computed blink samples against all events in the *Mod.eve file and re-codes events that have blinks within them to 200, which is the 'Blink' event found in *.ave
##Calls python script 'makeCovFiles.py' to make the covariance parameter files
##Currently doing the averages both with the projections applied and without, because the projections are good for MEG but for EEG it displays with average reference, which makes it look different than our previous data.
##Calls python script 'countEvents.py' which outputs a text file in the 'logs' folder called '...ArtReject.txt'. This is useful because compares the number of events in the file originally with the number that end up in the average.

When you've run through all the subjects, run Matlab script 'MEG/scripts/avg_across_subjs.m' to make a grand-average.

=====Anatomy=====
#Run /scripts/preAnat
##makes the BEM surfaces from flash5
##makes source space model from the surfaces
#Manually check the surfaces to make sure they look fine
##tkmedit subjnum T1.mgz, then load surfaces to view
#Manually coregister the MEG and MRI in mne_analyze

=====Make inverse solutions=====
#Run /scripts/makeInv $subjID. This depends on preAnat, the head localization coordinates from preProc, and the cov matrices from preProc.
#Run /scripts/makeSTC $subjID to store the source solutions in an 'stc' file. This depends on the average data from preProc, the surfaces created by preAnat, and the transformations created by makeInv.
#Run /scripts/statSTC(subjList) in Matlab to run massive univariate analysis without correction, for eyeballing data

==Analysis==
See [[SemPrMM_1st_Level]] for a detailed description of how to process a subject to the 1st-level statistics. <br>
See [[SemPrMM_Analysis_Settings]] for a detailed description of all the settings we use in the numerous programs for analysis.


===SPM Analysis Steps===
#Define linear model
##The onsets of the events used in the model are stored in functionals/subjID/info.txt. This includes the regressor for incorrect responses.
##The six motion parameters and any outliers are stored in functionals/subjID/paradigm/runNum/art_regression_outliers_and_movement_ATLLoc1.mat
##High-pass filter cutoff at 128 seconds
##No derivatives
##AR(1) model used to minimize effects of serial correlations

===fsFast Analysis Steps===
#Define linear model
##The onsets of the events used in the model are stored in functionals/subjID/info.txt
##Use three orthogonalized motion vectors as nuisance variables, the first 3 columns in subjID/paradigm/runNum/mcprextreg.
##Define outlier time points as 'time points to exclude'
##AR(1) model used with temporal whitening

===SPM Contrasts===
====ATLLoc====
# Sentences
# Nouns
# Consonant Strings
# S-N
# N-S
# S-C
# C-S
# N-C
# C-N

====MaskedMM====
# Directly Related
# Indirectly Related
# Unrelated
# Insect Prime
# Insect Target
# Direct vs Unrelated
# Unrelated vs Direct

====BaleenLP====
# Related Target
# Unrelated Target
# Unrelated Filler
# Animal Target
# Animal Prime
# Related vs Unrelated
# Unrelated vs Related

====BaleenHP====
# HP Related
# HP Unrelated
# HP Related Filler
# HP Unrelated Filler
# HP Animal Target
# HP Animal Prime
# HP Related vs Unrelated
# HP Unrelated vs Related

====AXCPT====
# AY
# BY
# BX
# AX
# AXvsBX
# BXvsAX
# AXvsAY
# AYvsAX

===MEG Procedures===
#Run the avgAcrossSubjs.m script in Matlab to create a grand-average sensor map for viewing in MNE.
#To create a grand-average in source space
##Create a .desc file in MEG/scripts listing the STC files to go into the average
##Run the command ''mne_average_estimates --desc xxx.desc''
#To create a grand-average difference map in source space
##Load the stc files into Matlab, subtract the data fields, and write result out to STC.
#To create a map of p-values in source space, use script statSTC.m

===Main comparisons of interest===

Theoretical - 
* The 2nd level comparison of the priming effect in the low RelProp block to the priming effect in the high RelProp block: (LoUnrel - LoRel) vs (HiUnrel - HiRel). This is the key theoretical comparison because by doing the subtraction, we factor out low-level differences between the first block and the second block.
* Animal probes in the low RelProp block vs animal probes in the high RelProp block. This is the comparison that shows a bigger late positivity for high RelProp.

Methodological - 
* Semantic priming effect (Unrel - rel) in MEG compared to fMRI
* Early sensory processing in MEG compared to fMRI
===ROI analysis===
We're interested in BA 20, 21, 22, 38, 39, 44, 45, and 47. Fortunately, FS automatically generates labels for BA 44 and 45. Unfortunately, it doesn't do the rest.
    cd /cluster/kuperberg/SemPrMM/MRI/structurals/subjects/fsaverage/label/
    mri_annotation2label --subject fsaverage --hemi lh --annotation ./lh.aparc.a2009s.annot --labelbase ./SemPrMM/MRI/structurals/subjects/fsaverage/label/aparc-lh
This makes 76 aparc-lh-%03d.label (eg aparc-lh-000.label -> aparc-lh-035.label) files.  <br>
After manually looking at these labels...
*    aparc-lh-009.label -> BA20
*    aparc-lh-015.label -> BA21 
*    aparc-lh-001.label -> BA22
